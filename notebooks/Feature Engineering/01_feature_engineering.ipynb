{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52815e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T09:18:45.400752Z",
     "iopub.status.busy": "2025-06-18T09:18:45.400347Z",
     "iopub.status.idle": "2025-06-18T09:18:46.366019Z",
     "shell.execute_reply": "2025-06-18T09:18:46.364489Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def rsi(series, period=14):\n",
    "    delta = series.diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.rolling(period, min_periods=period).mean()\n",
    "    avg_loss = loss.rolling(period, min_periods=period).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "\n",
    "def atr(high, low, close, period=14):\n",
    "    high_low = high - low\n",
    "    high_close = (high - close.shift()).abs()\n",
    "    low_close = (low - close.shift()).abs()\n",
    "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    return tr.rolling(period, min_periods=period).mean()\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77263c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T09:18:46.373411Z",
     "iopub.status.busy": "2025-06-18T09:18:46.372952Z",
     "iopub.status.idle": "2025-06-18T09:18:47.847771Z",
     "shell.execute_reply": "2025-06-18T09:18:47.846140Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7684/3218521255.py:4: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.asfreq('12H')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(df[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      3\u001b[39m df.set_index(\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43masfreq\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m12H\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/core/generic.py:9250\u001b[39m, in \u001b[36mNDFrame.asfreq\u001b[39m\u001b[34m(self, freq, method, how, normalize, fill_value)\u001b[39m\n\u001b[32m   9143\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   9144\u001b[39m \u001b[33;03mConvert time series to specified frequency.\u001b[39;00m\n\u001b[32m   9145\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   9246\u001b[39m \u001b[33;03m2000-01-01 00:03:00    3.0\u001b[39;00m\n\u001b[32m   9247\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   9248\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresample\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m asfreq\n\u001b[32m-> \u001b[39m\u001b[32m9250\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masfreq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9251\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9257\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/core/resample.py:2837\u001b[39m, in \u001b[36masfreq\u001b[39m\u001b[34m(obj, freq, method, how, normalize, fill_value)\u001b[39m\n\u001b[32m   2835\u001b[39m dti = date_range(obj.index.min(), obj.index.max(), freq=freq, unit=unit)\n\u001b[32m   2836\u001b[39m dti.name = obj.index.name\n\u001b[32m-> \u001b[39m\u001b[32m2837\u001b[39m new_obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2838\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[32m   2839\u001b[39m     new_obj.index = new_obj.index.normalize()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/core/frame.py:5385\u001b[39m, in \u001b[36mDataFrame.reindex\u001b[39m\u001b[34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[39m\n\u001b[32m   5366\u001b[39m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[32m   5367\u001b[39m     NDFrame.reindex,\n\u001b[32m   5368\u001b[39m     klass=_shared_doc_kwargs[\u001b[33m\"\u001b[39m\u001b[33mklass\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   5383\u001b[39m     tolerance=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5384\u001b[39m ) -> DataFrame:\n\u001b[32m-> \u001b[39m\u001b[32m5385\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5389\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5396\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/core/generic.py:5629\u001b[39m, in \u001b[36mNDFrame.reindex\u001b[39m\u001b[34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[39m\n\u001b[32m   5626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reindex_multi(axes, copy, fill_value)\n\u001b[32m   5628\u001b[39m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5629\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5630\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[32m   5631\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mreindex\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/core/generic.py:5652\u001b[39m, in \u001b[36mNDFrame._reindex_axes\u001b[39m\u001b[34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[39m\n\u001b[32m   5649\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   5651\u001b[39m ax = \u001b[38;5;28mself\u001b[39m._get_axis(a)\n\u001b[32m-> \u001b[39m\u001b[32m5652\u001b[39m new_index, indexer = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[32m   5654\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5656\u001b[39m axis = \u001b[38;5;28mself\u001b[39m._get_axis_number(a)\n\u001b[32m   5657\u001b[39m obj = obj._reindex_with_indexers(\n\u001b[32m   5658\u001b[39m     {axis: [new_index, indexer]},\n\u001b[32m   5659\u001b[39m     fill_value=fill_value,\n\u001b[32m   5660\u001b[39m     copy=copy,\n\u001b[32m   5661\u001b[39m     allow_dups=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   5662\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pandas/core/indexes/base.py:4436\u001b[39m, in \u001b[36mIndex.reindex\u001b[39m\u001b[34m(self, target, method, level, limit, tolerance)\u001b[39m\n\u001b[32m   4433\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot handle a non-unique multi-index!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4434\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_unique:\n\u001b[32m   4435\u001b[39m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4436\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4437\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4438\u001b[39m     indexer, _ = \u001b[38;5;28mself\u001b[39m.get_indexer_non_unique(target)\n",
      "\u001b[31mValueError\u001b[39m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_parquet('data/06data.parquet')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.set_index('timestamp', inplace=True)\n",
    "df = df.asfreq('12H')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a5658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_base_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df = df.set_index('timestamp')\n",
    "        df = df.asfreq('12H')\n",
    "\n",
    "    close = df['token_close_usd']\n",
    "    high = df.get('high_usd', df.get('high'))\n",
    "    low = df.get('low_usd', df.get('low'))\n",
    "    volume = df.get('volume', df.get('token_volume_usd'))\n",
    "\n",
    "    df['logret_12h'] = np.log(close / close.shift(1))\n",
    "    df['logret_36h'] = np.log(close / close.shift(3))\n",
    "\n",
    "    delta = close.diff()\n",
    "    up = delta.clip(lower=0)\n",
    "    down = -delta.clip(upper=0)\n",
    "    ema_up = up.ewm(alpha=1/14, adjust=False).mean()\n",
    "    ema_down = down.ewm(alpha=1/14, adjust=False).mean()\n",
    "    df['rsi_14'] = 100 * ema_up / (ema_up + ema_down)\n",
    "\n",
    "    df['roc_3'] = (close / close.shift(3) - 1) * 100\n",
    "    df['realized_vol_36h'] = df['logret_12h'].rolling(3).std(ddof=0)\n",
    "\n",
    "    tr = pd.concat([\n",
    "        high - low,\n",
    "        (high - close.shift()).abs(),\n",
    "        (low - close.shift()).abs()\n",
    "    ], axis=1).max(axis=1)\n",
    "    df['atr_14'] = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "\n",
    "    if {'best_ask', 'best_bid'}.issubset(df.columns):\n",
    "        mid = (df['best_ask'] + df['best_bid']) / 2\n",
    "        df['spread'] = (df['best_ask'] - df['best_bid']) / mid\n",
    "    else:\n",
    "        df['spread'] = np.nan\n",
    "\n",
    "    if {'bid_size', 'ask_size'}.issubset(df.columns):\n",
    "        df['depth'] = df['bid_size'] + df['ask_size']\n",
    "    else:\n",
    "        df['depth'] = np.nan\n",
    "\n",
    "    df['vol_spike'] = df['volume'] / df['volume'].rolling(14, min_periods=1).mean()\n",
    "\n",
    "    uniq_wallets = df.get('unique_wallets', df.get('holder_count'))\n",
    "    if uniq_wallets is not None:\n",
    "        df['delta_wallets'] = uniq_wallets.diff()\n",
    "    else:\n",
    "        df['delta_wallets'] = np.nan\n",
    "\n",
    "    df['tx_count_12h'] = df.get('tx_count', df.get('network_tx_count'))\n",
    "\n",
    "    if 'sol_close_usd' in df.columns:\n",
    "        df['ret_SOL'] = df['sol_close_usd'].pct_change() * 100\n",
    "    if 'btc_close_usd' in df.columns:\n",
    "        df['ret_BTC'] = df['btc_close_usd'].pct_change() * 100\n",
    "    if 'eth_close_usd' in df.columns:\n",
    "        df['ret_ETH'] = df['eth_close_usd'].pct_change() * 100\n",
    "    if 'DeFi_TVL' in df.columns:\n",
    "        df['tvl_dev'] = (df['DeFi_TVL'] / df['DeFi_TVL'].rolling(14).mean() - 1) * 100\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86699f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = compute_base_features(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e74a2f6",
   "metadata": {},
   "source": [
    "## Base Feature Overview\n",
    "The `compute_base_features` function adds the following fields:\n",
    "- **logret_12h** – log return of the close over the last 12 hours.\n",
    "- **logret_36h** – log return over the previous three 12‑hour bars.\n",
    "- **rsi_14** – 14‑period Relative Strength Index using closing prices.\n",
    "- **roc_3** – 3‑period Rate of Change of the close (percent).\n",
    "- **realized_vol_36h** – rolling 36‑hour standard deviation of `logret_12h`.\n",
    "- **atr_14** – 14‑period Average True Range.\n",
    "- **spread** – relative bid/ask spread.\n",
    "- **depth** – combined bid and ask size.\n",
    "- **vol_spike** – ratio of volume to its 14‑period average.\n",
    "- **delta_wallets** – change in unique wallet count.\n",
    "- **tx_count_12h** – transaction count for the bar.\n",
    "- **ret_SOL** – SOL percentage return.\n",
    "- **ret_BTC** – BTC percentage return.\n",
    "- **ret_ETH** – ETH percentage return.\n",
    "- **tvl_dev** – deviation of DeFi TVL from its 14‑period mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e341bf75",
   "metadata": {},
   "source": [
    "\n",
    "###\n",
    "# PLACEHOLDER: ADDITIONAL FEATURE ENGINEERING\n",
    "###\n",
    "# For example, you might compute:\n",
    "#  - Rolling skewness/kurtosis of logret_12h (tail-risk indicators)\n",
    "#  - Regime flags (volatility regime, trend regime)\n",
    "#  - Interaction terms (price × volume, spread × vol_spike)\n",
    "#  - Composite indices (PCA on SOL/BTC/ETH returns)\n",
    "#  - Sentiment metrics (social_mentions rolling averages or z-scores)\n",
    "#  - Price momentum buckets (quantile-based bins)\n",
    "#  - Missing-data flags and imputation indicators\n",
    "#  - Any other domain-inspired signals you see fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46858b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_advanced_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    high = df.get('high_usd', df.get('high'))\n",
    "    low = df.get('low_usd', df.get('low'))\n",
    "    open_ = df.get('open_usd', df.get('open'))\n",
    "    close = df['token_close_usd']\n",
    "    volume = df.get('token_volume_usd', df.get('volume'))\n",
    "\n",
    "    hl = np.log(df['high'] / df['low'])\n",
    "    var_parkinson = hl.pow(2).rolling(3).sum() / (4 * np.log(2) * 3)\n",
    "    df['parkinson_vol_36h'] = np.sqrt(var_parkinson)\n",
    "\n",
    "    oc = np.log(df['close'] / df['close'].shift(1))\n",
    "    hl = np.log(df['high'] / df['low'])\n",
    "    gk_var = 0.5 * hl.pow(2) - (2 * np.log(2) - 1) * oc.pow(2)\n",
    "    df['gk_vol_36h'] = np.sqrt(gk_var.rolling(3).mean())\n",
    "\n",
    "    df['amihud_illiq_12h'] = (df['logret_12h'].abs() / df['volume']).rolling(3).mean()\n",
    "\n",
    "    if {'new_token_accounts', 'holder_count'}.issubset(df.columns):\n",
    "        df['new_accounts_ratio'] = df['new_token_accounts'] / df['holder_count']\n",
    "\n",
    "    if {'network_tx_count', 'holder_count'}.issubset(df.columns):\n",
    "        df['tx_per_account'] = df['network_tx_count'] / df['holder_count']\n",
    "\n",
    "    if 'delta_wallets' in df.columns and 'holder_count' in df.columns:\n",
    "        df['wallet_growth_rate'] = df['delta_wallets'] / df['holder_count']\n",
    "\n",
    "    if {'ret_SOL', 'logret_12h'}.issubset(df.columns):\n",
    "        df['corr_SOL_36h'] = df['logret_12h'].rolling(3).corr(df['ret_SOL'])\n",
    "    if {'ret_BTC', 'logret_12h'}.issubset(df.columns):\n",
    "        df['corr_BTC_36h'] = df['logret_12h'].rolling(3).corr(df['ret_BTC'])\n",
    "    if {'ret_ETH', 'logret_12h'}.issubset(df.columns):\n",
    "        df['corr_ETH_36h'] = df['logret_12h'].rolling(3).corr(df['ret_ETH'])\n",
    "\n",
    "    vol_mean = df['volume'].rolling(14).mean()\n",
    "    vol_std = df['volume'].rolling(14).std(ddof=0)\n",
    "    df['vol_zscore'] = (df['volume'] - vol_mean) / vol_std\n",
    "\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    df['hour'] = df.index.hour\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e985e1f4",
   "metadata": {},
   "source": [
    "## Advanced Feature Overview\n",
    "The `compute_advanced_features` function augments the dataset with:\n",
    "- **parkinson_vol_36h** – 36‑hour Parkinson volatility using high and low prices.\n",
    "- **gk_vol_36h** – 36‑hour Garman‑Klass volatility from OHLC bars.\n",
    "- **amihud_illiq_12h** – Amihud illiquidity over the last 36 hours.\n",
    "- **new_accounts_ratio** – new token accounts relative to current holders.\n",
    "- **tx_per_account** – network transactions per holder.\n",
    "- **wallet_growth_rate** – change in wallet count scaled by total holders.\n",
    "- **corr_SOL_36h** – rolling correlation of token and SOL returns.\n",
    "- **corr_BTC_36h** – rolling correlation of token and BTC returns.\n",
    "- **corr_ETH_36h** – rolling correlation of token and ETH returns.\n",
    "- **vol_zscore** – volume z‑score versus a 14‑period mean and std.\n",
    "- **day_of_week** – day of week (0=Monday).\n",
    "- **hour** – bar hour of day (0 or 12).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa1339d",
   "metadata": {},
   "source": [
    "## Additional Feature Overview\n",
    "The `compute_additional_features` function adds:\n",
    "- **skew_36h** – rolling 36‑hour skewness of `logret_12h`.\n",
    "- **kurt_36h** – rolling 36‑hour kurtosis of `logret_12h`.\n",
    "- **vol_regime** – 1 if short volatility exceeds its 14‑period mean.\n",
    "- **trend_regime** – 1 if close is above its 50‑period average.\n",
    "- **price_volume** – close multiplied by volume.\n",
    "- **spread_vol** – bid/ask spread times `vol_spike`.\n",
    "- **market_pc1** – first principal component of SOL/BTC/ETH returns.\n",
    "- **momentum_bucket** – quantile bin of 3‑period ROC.\n",
    "- **volume_missing** – flag for missing volume.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed9f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_additional_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['skew_36h'] = df['logret_12h'].rolling(3).skew()\n",
    "    df['kurt_36h'] = df['logret_12h'].rolling(3).kurt()\n",
    "    vol_mean_36h = df['realized_vol_36h'].rolling(14).mean()\n",
    "    df['vol_regime'] = (df['realized_vol_36h'] > vol_mean_36h).astype(int)\n",
    "    price_mean_72h = df['token_close_usd'].rolling(6).mean()\n",
    "    df['trend_regime'] = (df['token_close_usd'] > price_mean_72h).astype(int)\n",
    "    if 'token_volume_usd' in df.columns:\n",
    "        df['price_volume'] = df['token_close_usd'] * df['token_volume_usd']\n",
    "    if {'spread', 'vol_spike'}.issubset(df.columns):\n",
    "        df['spread_vol'] = df['spread'] * df['vol_spike']\n",
    "    if {'ret_SOL','ret_BTC','ret_ETH'}.issubset(df.columns):\n",
    "        from sklearn.decomposition import PCA\n",
    "        rets = df[['ret_SOL','ret_BTC','ret_ETH']]\n",
    "        pc1 = [np.nan] * len(rets)\n",
    "        pca = PCA(n_components=1)\n",
    "        for i in range(13, len(rets)):\n",
    "            window = rets.iloc[i-13:i+1].dropna()\n",
    "            if len(window) == 14:\n",
    "                pca.fit(window)\n",
    "                pc1[i] = pca.transform(rets.iloc[[i]])[0,0]\n",
    "        df['market_pc1'] = pc1\n",
    "    if 'roc_3' in df.columns:\n",
    "        df['momentum_bucket'] = pd.qcut(\n",
    "            df['roc_3'].rank(method='first'),\n",
    "            q=5,\n",
    "            labels=False,\n",
    "            duplicates='drop'\n",
    "        )\n",
    "    if 'token_volume_usd' in df.columns:\n",
    "        df['volume_missing'] = df['token_volume_usd'].isna().astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33c42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute base and advanced features\n",
    "\n",
    "df_feat = compute_base_features(df)\n",
    "df_feat = compute_advanced_features(df_feat)\n",
    "df_feat = compute_additional_features(df_feat)\n",
    "\n",
    "# Save augmented dataset after chnages\n",
    "df_feat.to_parquet('data/07data.parquet')\n",
    "\n",
    "df_feat.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903afad7",
   "metadata": {},
   "source": [
    "## Feature Documentation\n",
    "\n",
    "### Momentum\n",
    "- **logret_12h**: log return over 12h capturing short-term momentum.\n",
    "- **logret_36h**: 36h cumulative log return signaling trend direction.\n",
    "- **roc_3**: 3-bar rate of change showing acceleration.\n",
    "- **rsi_14**: Wilder RSI measuring overbought or oversold conditions.\n",
    "\n",
    "### Volatility\n",
    "- **realized_vol_36h**: population std of log returns as realized volatility.\n",
    "- **atr_14**: Wilder's Average True Range representing trading range.\n",
    "- **parkinson_vol_36h**: volatility from high/low ranges.\n",
    "- **gk_vol_36h**: Garman–Klass OHLC volatility.\n",
    "- **vol_zscore**: standardized volume vs 14-bar mean.\n",
    "- **skew_36h**: return skewness capturing asymmetry.\n",
    "- **kurt_36h**: return kurtosis measuring fat tails.\n",
    "\n",
    "### Liquidity\n",
    "- **spread**: relative bid-ask spread proxying for transaction cost.\n",
    "- **depth**: summed bid and ask size as available liquidity.\n",
    "- **vol_spike**: volume divided by its 14-bar average.\n",
    "- **amihud_illiq_12h**: price impact per volume unit.\n",
    "- **price_volume**: price-volume interaction.\n",
    "- **spread_vol**: spread multiplied by volume spike.\n",
    "- **volume_missing**: flag when volume is missing.\n",
    "\n",
    "### On-Chain\n",
    "- **delta_wallets**: change in unique wallet count.\n",
    "- **tx_count_12h**: on-chain transaction count.\n",
    "- **tvl_dev**: DeFi TVL deviation from 14-bar mean (%).\n",
    "- **new_accounts_ratio**: share of new accounts among holders.\n",
    "- **tx_per_account**: transactions per holder.\n",
    "- **wallet_growth_rate**: wallet growth relative to holders.\n",
    "\n",
    "### Cross-Asset\n",
    "- **ret_SOL**, **ret_BTC**, **ret_ETH**: returns of major assets.\n",
    "- **corr_SOL_36h**, **corr_BTC_36h**, **corr_ETH_36h**: rolling correlations with those returns.\n",
    "- **market_pc1**: first PCA component of SOL/BTC/ETH returns.\n",
    "\n",
    "### Regimes\n",
    "- **vol_regime**: indicator for high volatility regime.\n",
    "- **trend_regime**: indicator for bullish trend.\n",
    "- **day_of_week**, **hour**: temporal effects.\n",
    "\n",
    "### Buckets\n",
    "- **momentum_bucket**: quantile bucket of short-term momentum.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
