{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba581ec",
   "metadata": {},
   "source": [
    "# V2 - Feature Engineering notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec29f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_parquet(\"C:/Users/james/OneDrive/Documents/GitHub/solana-qrf-interval-forecasting/data/06data.parquet\")\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.sort_values(['token', 'timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff265113",
   "metadata": {},
   "source": [
    "Base indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e49c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi(series, period=14):\n",
    "    delta = series.diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.ewm(alpha=1/period, min_periods=period, adjust=False).mean()\n",
    "    avg_loss = loss.ewm(alpha=1/period, min_periods=period, adjust=False).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    return 100 - 100 / (1 + rs)\n",
    "def atr(high, low, close, period=14):\n",
    "    high_low = high - low\n",
    "    high_close = (high - close.shift()).abs()\n",
    "    low_close = (low - close.shift()).abs()\n",
    "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    return tr.rolling(period, min_periods=period).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea7cc4b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94718c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_base_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    new_cols = [\n",
    "        'logret_12h', 'logret_36h', 'rsi_14', 'roc_3', 'realized_vol_36h',\n",
    "        'atr_14', 'spread', 'depth', 'vol_spike', 'delta_wallets',\n",
    "        'tx_count_12h', 'ret_SOL', 'ret_BTC', 'ret_ETH', 'tvl_dev'\n",
    "    ]\n",
    "    df.drop(columns=[c for c in new_cols if c in df.columns], inplace=True, errors='ignore')\n",
    "\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df.sort_values(['token', 'timestamp'], inplace=True)\n",
    "    g = df.groupby('token')\n",
    "    volume = df.get('token_volume_usd', df.get('volume'))\n",
    "\n",
    "    df['logret_12h'] = g['token_close_usd'].transform(lambda x: np.log(x / x.shift(1)))\n",
    "    df['logret_36h'] = g['token_close_usd'].transform(lambda x: np.log(x / x.shift(3)))\n",
    "    df['rsi_14'] = g['token_close_usd'].transform(lambda x: rsi(x, 14))\n",
    "    df['roc_3'] = g['token_close_usd'].transform(lambda x: (x / x.shift(3) - 1) * 100)\n",
    "    df['realized_vol_36h'] = g['logret_12h'].transform(lambda x: x.rolling(3).std())\n",
    "    df['atr_14'] = df.groupby('token', group_keys=False).apply(lambda grp: atr(grp.get('high_usd', grp.get('high')), grp.get('low_usd', grp.get('low')), grp['token_close_usd'], 14))\n",
    "\n",
    "    if {'best_ask', 'best_bid'}.issubset(df.columns):\n",
    "        mid = (df['best_ask'] + df['best_bid']) / 2\n",
    "        df['spread'] = (df['best_ask'] - df['best_bid']) / mid\n",
    "    else:\n",
    "        df['spread'] = np.nan\n",
    "\n",
    "    if {'bid_size', 'ask_size'}.issubset(df.columns):\n",
    "        df['depth'] = df['bid_size'] + df['ask_size']\n",
    "    else:\n",
    "        df['depth'] = np.nan\n",
    "\n",
    "    if volume is not None:\n",
    "        df['vol_spike'] = g[volume.name].transform(lambda x: x / x.rolling(14).mean())\n",
    "    else:\n",
    "        df['vol_spike'] = np.nan\n",
    "\n",
    "    uniq_wallets = df.get('unique_wallets', df.get('holder_count'))\n",
    "    if uniq_wallets is not None:\n",
    "        df['delta_wallets'] = g[uniq_wallets.name].transform(lambda x: x.diff())\n",
    "    else:\n",
    "        df['delta_wallets'] = np.nan\n",
    "\n",
    "    df['tx_count_12h'] = df.get('tx_count', df.get('network_tx_count'))\n",
    "\n",
    "    if 'sol_close_usd' in df.columns:\n",
    "        df['ret_SOL'] = df['sol_close_usd'].pct_change() * 100\n",
    "    if 'btc_close_usd' in df.columns:\n",
    "        df['ret_BTC'] = df['btc_close_usd'].pct_change() * 100\n",
    "    if 'eth_close_usd' in df.columns:\n",
    "        df['ret_ETH'] = df['eth_close_usd'].pct_change() * 100\n",
    "    if 'tvl_usd' in df.columns:\n",
    "        df['tvl_dev'] = (df['tvl_usd'] / df['tvl_usd'].rolling(14).mean() - 1) * 100\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0087716",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compute_base_features(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2698c1",
   "metadata": {},
   "source": [
    "## Base Feature Overview\n",
    "### The `compute_base_features` function adds the following fields:\n",
    "- **logret_12h** – log return of the close over the last 12 hours.\n",
    "- **logret_36h** – log return over the previous three 12‑hour bars.\n",
    "- **rsi_14** – 14‑period Relative Strength Index using closing prices.\n",
    "- **roc_3** – 3‑period Rate of Change of the close (percent).\n",
    "- **realized_vol_36h** – rolling 36‑hour standard deviation of `logret_12h`.\n",
    "- **atr_14** – 14‑period Average True Range.\n",
    "- **spread** – relative bid/ask spread.\n",
    "- **depth** – combined bid and ask size.\n",
    "- **vol_spike** – ratio of volume to its 14‑period average.\n",
    "- **delta_wallets** – change in unique wallet count.\n",
    "- **tx_count_12h** – transaction count for the bar.\n",
    "- **ret_SOL** – SOL percentage return.\n",
    "- **ret_BTC** – BTC percentage return.\n",
    "- **ret_ETH** – ETH percentage return.\n",
    "- **tvl_dev** – deviation of DeFi TVL from its 14‑period mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2fd65",
   "metadata": {},
   "source": [
    "# Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac49ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_advanced_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    new_cols = [\n",
    "        'parkinson_vol_36h', 'gk_vol_36h', 'amihud_illiq_12h',\n",
    "        'new_accounts_ratio', 'tx_per_account', 'wallet_growth_rate',\n",
    "        'corr_SOL_36h', 'corr_BTC_36h', 'corr_ETH_36h', 'vol_zscore',\n",
    "        'day_of_week', 'hour'\n",
    "    ]\n",
    "    df.drop(columns=[c for c in new_cols if c in df.columns], inplace=True, errors='ignore')\n",
    "\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df.sort_values(['token', 'timestamp'], inplace=True)\n",
    "    g = df.groupby('token')\n",
    "\n",
    "    high = df.get('high_usd', df.get('high'))\n",
    "    low = df.get('low_usd', df.get('low'))\n",
    "    open_ = df.get('open_usd', df.get('open'))\n",
    "    volume = df.get('token_volume_usd', df.get('volume'))\n",
    "\n",
    "    df['parkinson_vol_36h'] = g.apply(lambda grp: (np.log(grp[high.name] / grp[low.name]) ** 2).rolling(3).mean().div(4 * np.log(2)).pow(0.5)).reset_index(level=0, drop=True)\n",
    "\n",
    "    df['gk_vol_36h'] = g.apply(lambda grp: (0.5 * np.log(grp[high.name] / grp[low.name]) ** 2 - (2 * np.log(2) - 1) * np.log(grp['token_close_usd'] / grp[open_.name]) ** 2).rolling(3).mean().pow(0.5)).reset_index(level=0, drop=True)\n",
    "\n",
    "    if volume is not None:\n",
    "        df['amihud_illiq_12h'] = g.apply(lambda grp: (grp['logret_12h'].abs() / grp[volume.name]).rolling(3).mean()).reset_index(level=0, drop=True)\n",
    "    else:\n",
    "        df['amihud_illiq_12h'] = np.nan\n",
    "\n",
    "    if {'new_token_accounts', 'holder_count'}.issubset(df.columns):\n",
    "        df['new_accounts_ratio'] = df['new_token_accounts'] / df['holder_count']\n",
    "\n",
    "    if {'network_tx_count', 'holder_count'}.issubset(df.columns):\n",
    "        df['tx_per_account'] = df['network_tx_count'] / df['holder_count']\n",
    "\n",
    "    if 'delta_wallets' in df.columns and 'holder_count' in df.columns:\n",
    "        df['wallet_growth_rate'] = df['delta_wallets'] / df['holder_count']\n",
    "\n",
    "    if {'ret_SOL', 'logret_12h'}.issubset(df.columns):\n",
    "        df['corr_SOL_36h'] = g.apply(lambda grp: grp['logret_12h'].rolling(3).corr(grp['ret_SOL'])).reset_index(level=0, drop=True)\n",
    "    if {'ret_BTC', 'logret_12h'}.issubset(df.columns):\n",
    "        df['corr_BTC_36h'] = g.apply(lambda grp: grp['logret_12h'].rolling(3).corr(grp['ret_BTC'])).reset_index(level=0, drop=True)\n",
    "    if {'ret_ETH', 'logret_12h'}.issubset(df.columns):\n",
    "        df['corr_ETH_36h'] = g.apply(lambda grp: grp['logret_12h'].rolling(3).corr(grp['ret_ETH'])).reset_index(level=0, drop=True)\n",
    "\n",
    "    if volume is not None:\n",
    "        df['vol_zscore'] = g[volume.name].transform(lambda x: (x - x.rolling(14).mean()) / x.rolling(14).std())\n",
    "\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb9b8ef",
   "metadata": {},
   "source": [
    "## Advanced Feature Overview\n",
    "#### The `compute_advanced_features` function augments the dataset with:\n",
    "- **parkinson_vol_36h** – 36‑hour Parkinson volatility using high and low prices.\n",
    "- **gk_vol_36h** – 36‑hour Garman‑Klass volatility from OHLC bars.\n",
    "- **amihud_illiq_12h** – Amihud illiquidity over the last 36 hours.\n",
    "- **new_accounts_ratio** – new token accounts relative to current holders.\n",
    "- **tx_per_account** – network transactions per holder.\n",
    "- **wallet_growth_rate** – change in wallet count scaled by total holders.\n",
    "- **corr_SOL_36h** – rolling correlation of token and SOL returns.\n",
    "- **corr_BTC_36h** – rolling correlation of token and BTC returns.\n",
    "- **corr_ETH_36h** – rolling correlation of token and ETH returns.\n",
    "- **vol_zscore** – volume z‑score versus a 14‑period mean and std.\n",
    "- **day_of_week** – day of week (0=Monday).\n",
    "- **hour** – bar hour of day (0 or 12)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c8834f",
   "metadata": {},
   "source": [
    "## Additional Feature Overview\n",
    "#### The `compute_additional_features` function adds:\n",
    "- **skew_36h** – rolling 36‑hour skewness of `logret_12h`.\n",
    "- **kurt_36h** – rolling 36‑hour kurtosis of `logret_12h`.\n",
    "- **vol_regime** – 1 if short volatility exceeds its 14‑period mean.\n",
    "- **trend_regime** – 1 if close is above its 50‑period average.\n",
    "- **price_volume** – close multiplied by volume.\n",
    "- **spread_vol** – bid/ask spread times `vol_spike`.\n",
    "- **market_pc1** – first principal component of SOL/BTC/ETH returns.\n",
    "- **momentum_bucket** – quantile bin of 3‑period ROC.\n",
    "- **volume_missing** – flag for missing volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacdb572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_additional_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    new_cols = [\n",
    "        'skew_36h', 'kurt_36h', 'vol_regime', 'trend_regime', 'price_volume',\n",
    "        'spread_vol', 'market_pc1', 'momentum_bucket', 'volume_missing'\n",
    "    ]\n",
    "    df.drop(columns=[c for c in new_cols if c in df.columns], inplace=True, errors='ignore')\n",
    "\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df.sort_values(['token', 'timestamp'], inplace=True)\n",
    "    g = df.groupby('token')\n",
    "    df['skew_36h'] = g['logret_12h'].transform(lambda x: x.rolling(3).skew())\n",
    "    df['kurt_36h'] = g['logret_12h'].transform(lambda x: x.rolling(3).kurt())\n",
    "    df['vol_regime'] = g['realized_vol_36h'].transform(lambda x: (x > x.rolling(14).mean()).astype(int))\n",
    "    df['trend_regime'] = g['token_close_usd'].transform(lambda x: (x > x.rolling(50).mean()).astype(int))\n",
    "    # Interaction terms\n",
    "    if 'token_volume_usd' in df.columns:\n",
    "        df['price_volume'] = df['token_close_usd'] * df['token_volume_usd']\n",
    "    if {'spread', 'vol_spike'}.issubset(df.columns):\n",
    "        df['spread_vol'] = df['spread'] * df['vol_spike']\n",
    "    # Rolling PCA first component of SOL/BTC/ETH returns\n",
    "    if {'ret_SOL','ret_BTC','ret_ETH'}.issubset(df.columns):\n",
    "        from sklearn.decomposition import PCA\n",
    "        rets = df[['ret_SOL','ret_BTC','ret_ETH']]\n",
    "        pc1 = [np.nan] * len(rets)\n",
    "        pca = PCA(n_components=1)\n",
    "        for i in range(13, len(rets)):\n",
    "            window = rets.iloc[i-13:i+1].dropna()\n",
    "            if len(window) == 14:\n",
    "                pca.fit(window)\n",
    "                pc1[i] = pca.transform(rets.iloc[[i]])[0,0]\n",
    "        df['market_pc1'] = pc1\n",
    "    # Momentum quantile bins\n",
    "    if 'roc_3' in df.columns:\n",
    "        df['momentum_bucket'] = pd.qcut(df['roc_3'].rank(method='first'), q=5, labels=False)\n",
    "    # Missing data flag\n",
    "    if 'token_volume_usd' in df.columns:\n",
    "        df['volume_missing'] = df['token_volume_usd'].isna().astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4141d6fc",
   "metadata": {},
   "source": [
    "## Compute base and advanced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904edfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compute_base_features(df)\n",
    "df = compute_advanced_features(df)\n",
    "df = compute_additional_features(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b5b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
