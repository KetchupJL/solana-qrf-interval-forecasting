{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "825cae1a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac794e64",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937d6511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, lightgbm as lgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from joblib import Parallel, delayed\n",
    "import os, itertools, warnings, json\n",
    "\n",
    "DATA_FILE = \"features_v1_tail.csv\"\n",
    "TARGET    = \"return_72h\"\n",
    "QUANTS    = [0.05, 0.25, 0.50, 0.75, 0.95]\n",
    "\n",
    "df = (pd.read_csv(DATA_FILE, parse_dates=[\"timestamp\"])\n",
    "        .sort_values([\"token\", \"timestamp\"])\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "cat_cols = [\"day_of_week\",\"momentum_bucket\", \"extreme_flag1\", \"tail_asym\",\"vol_regime\", \"token\"]\n",
    "num_cols = [c for c in df.columns\n",
    "            if c not in cat_cols + [\"timestamp\", TARGET]]\n",
    "\n",
    "# one-hot → dense matrix; LightGBM handles NaN in numeric naturally\n",
    "pre = ColumnTransformer([\n",
    "        (\"cats\", OneHotEncoder(drop=\"first\",\n",
    "                               handle_unknown=\"ignore\",\n",
    "                               sparse_output=False), cat_cols)\n",
    "      ],\n",
    "      remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ada1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN, CAL, TEST = 120, 24, 6     # bars (~60d, 12d, 3d)\n",
    "\n",
    "def rolling_splits(idx):\n",
    "    for start in range(0, len(idx) - (TRAIN + CAL + TEST) + 1, TEST):\n",
    "        tr = idx[start : start + TRAIN]\n",
    "        cal = idx[start + TRAIN : start + TRAIN + CAL]\n",
    "        te = idx[start + TRAIN + CAL : start + TRAIN + CAL + TEST]\n",
    "        if len(te) == TEST:\n",
    "            yield tr, cal, te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab6130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_one_fold(g, tr_idx, cal_idx, te_idx):\n",
    "    \"\"\"\n",
    "    Fit LightGBM-quantile on one rolling window and return\n",
    "    • fold_pred : list[dict]  (row-level predictions)\n",
    "    • fold_res  : list[dict]  (fold-level pinball loss)\n",
    "    \"\"\"\n",
    "    # ── matrices ─────────────────────────────────────────\n",
    "    X_tr  = pre.fit_transform(g.loc[tr_idx, cat_cols + num_cols])\n",
    "    y_tr  = g.loc[tr_idx, TARGET].values\n",
    "    X_cal = pre.transform(g.loc[cal_idx, cat_cols + num_cols])\n",
    "    y_cal = g.loc[cal_idx, TARGET].values\n",
    "    X_te  = pre.transform(g.loc[te_idx, cat_cols + num_cols])\n",
    "    y_te  = g.loc[te_idx, TARGET].values\n",
    "\n",
    "    token_id = g[\"token\"].iloc[0]      # ← safe token label\n",
    "\n",
    "    fold_pred, fold_res = [], []\n",
    "\n",
    "    for tau in QUANTS:\n",
    "        mdl = lgb.LGBMRegressor(\n",
    "            objective=\"quantile\", alpha=tau,\n",
    "            n_estimators=500, learning_rate=0.05,\n",
    "            max_depth=-1, subsample=0.9, colsample_bytree=0.9,\n",
    "            min_child_samples=20, random_state=42\n",
    "        )\n",
    "        mdl.fit(X_tr, y_tr)\n",
    "\n",
    "        # ── base predictions ─────────────────────────────\n",
    "        cal_hat = mdl.predict(X_cal)\n",
    "        te_hat  = mdl.predict(X_te)\n",
    "\n",
    "        # ── split-conformal adjustment ───────────────────\n",
    "        resid = y_cal - cal_hat\n",
    "        if tau < 0.5:\n",
    "            adj = np.quantile(np.maximum(resid, 0), 1 - tau)\n",
    "            te_adj = te_hat - adj\n",
    "        elif tau > 0.5:\n",
    "            adj = np.quantile(np.maximum(-resid, 0), 1 - (1 - tau))\n",
    "            te_adj = te_hat + adj\n",
    "        else:                       # τ = 0.50\n",
    "            te_adj = te_hat\n",
    "\n",
    "        # ── per-row predictions ──────────────────────────\n",
    "        fold_pred.extend({\n",
    "            \"timestamp\": g.loc[i, \"timestamp\"],\n",
    "            \"token\":     token_id,\n",
    "            \"tau\":       tau,\n",
    "            \"y_true\":    yt,\n",
    "            \"y_pred\":    yp\n",
    "        } for i, yt, yp in zip(te_idx, y_te, te_adj))\n",
    "\n",
    "        # ── fold-level pinball loss ──────────────────────\n",
    "        err = y_te - te_adj\n",
    "        pin = np.maximum(tau*err, (tau-1)*err).mean()\n",
    "        fold_res.append({\n",
    "            \"token\":   token_id,\n",
    "            \"tau\":     tau,\n",
    "            \"pinball\": pin\n",
    "        })\n",
    "\n",
    "    return fold_pred, fold_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d879e5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=23)]: Using backend LokyBackend with 23 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m preds, metrics\n\u001b[32m      8\u001b[39m n_jobs = \u001b[38;5;28mmax\u001b[39m(os.cpu_count()-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_token\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtoken\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m preds   = \u001b[38;5;28mlist\u001b[39m(itertools.chain.from_iterable(r[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results))\n\u001b[32m     14\u001b[39m metrics = \u001b[38;5;28mlist\u001b[39m(itertools.chain.from_iterable(r[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\james\\OneDrive\\Documents\\GitHub\\solana-qrf-interval-forecasting\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\james\\OneDrive\\Documents\\GitHub\\solana-qrf-interval-forecasting\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\james\\OneDrive\\Documents\\GitHub\\solana-qrf-interval-forecasting\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def run_token(tok, grp):\n",
    "    preds, metrics = [], []\n",
    "    for tr, cal, te in rolling_splits(grp.index):\n",
    "        p, m = fit_one_fold(grp, tr, cal, te)\n",
    "        preds.extend(p); metrics.extend(m)\n",
    "    return preds, metrics\n",
    "\n",
    "n_jobs = max(os.cpu_count()-1, 1)\n",
    "results = Parallel(n_jobs=n_jobs, verbose=5)(\n",
    "    delayed(run_token)(tok, grp.reset_index(drop=True))\n",
    "    for tok, grp in df.groupby(\"token\"))\n",
    "\n",
    "preds   = list(itertools.chain.from_iterable(r[0] for r in results))\n",
    "metrics = list(itertools.chain.from_iterable(r[1] for r in results))\n",
    "\n",
    "pd.DataFrame(preds).to_csv(\"stage7_lgb_preds.csv\", index=False)\n",
    "pd.DataFrame(metrics).to_csv(\"stage7_lgb_pinball.csv\", index=False)\n",
    "\n",
    "print(pd.DataFrame(metrics)\n",
    "        .groupby(\"tau\")[\"pinball\"].mean()\n",
    "        .round(4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
