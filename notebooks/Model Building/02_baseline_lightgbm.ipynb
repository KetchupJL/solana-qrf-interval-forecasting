{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "825cae1a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac794e64",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "937d6511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, lightgbm as lgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from joblib import Parallel, delayed\n",
    "import os, itertools, warnings, json\n",
    "\n",
    "DATA_FILE = \"features_v1_tail.csv\"\n",
    "TARGET    = \"return_72h\"\n",
    "QUANTS    = [0.05, 0.25, 0.50, 0.75, 0.95]\n",
    "\n",
    "df = (pd.read_csv(DATA_FILE, parse_dates=[\"timestamp\"])\n",
    "        .sort_values([\"token\", \"timestamp\"])\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "cat_cols = [\"day_of_week\",\"momentum_bucket\", \"extreme_flag1\", \"tail_asym\",\"vol_regime\", \"token\"]\n",
    "num_cols = [c for c in df.columns\n",
    "            if c not in cat_cols + [\"timestamp\", TARGET]]\n",
    "\n",
    "# one-hot → dense matrix; LightGBM handles NaN in numeric naturally\n",
    "pre = ColumnTransformer([\n",
    "        (\"cats\", OneHotEncoder(drop=\"first\",\n",
    "                               handle_unknown=\"ignore\",\n",
    "                               sparse_output=False), cat_cols)\n",
    "      ],\n",
    "      remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562ada1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN, CAL, TEST = 120, 24, 6     # bars (~60d, 12d, 3d)\n",
    "\n",
    "def rolling_splits(idx):\n",
    "    for start in range(0, len(idx) - (TRAIN + CAL + TEST) + 1, TEST):\n",
    "        tr = idx[start : start + TRAIN]\n",
    "        cal = idx[start + TRAIN : start + TRAIN + CAL]\n",
    "        te = idx[start + TRAIN + CAL : start + TRAIN + CAL + TEST]\n",
    "        if len(te) == TEST:\n",
    "            yield tr, cal, te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceab6130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_one_fold(g, tr_idx, cal_idx, te_idx):\n",
    "    \"\"\"\n",
    "    Fit LightGBM-quantile on one rolling window and return\n",
    "    • fold_pred : list[dict]  (row-level predictions)\n",
    "    • fold_res  : list[dict]  (fold-level pinball loss)\n",
    "    \"\"\"\n",
    "    # ── matrices ─────────────────────────────────────────\n",
    "    X_tr  = pre.fit_transform(g.loc[tr_idx, cat_cols + num_cols])\n",
    "    y_tr  = g.loc[tr_idx, TARGET].values\n",
    "    X_cal = pre.transform(g.loc[cal_idx, cat_cols + num_cols])\n",
    "    y_cal = g.loc[cal_idx, TARGET].values\n",
    "    X_te  = pre.transform(g.loc[te_idx, cat_cols + num_cols])\n",
    "    y_te  = g.loc[te_idx, TARGET].values\n",
    "\n",
    "    token_id = g[\"token\"].iloc[0]      # ← safe token label\n",
    "\n",
    "    fold_pred, fold_res = [], []\n",
    "\n",
    "    for tau in QUANTS:\n",
    "        mdl = lgb.LGBMRegressor(\n",
    "            objective=\"quantile\", alpha=tau,\n",
    "            n_estimators=500, learning_rate=0.05,\n",
    "            max_depth=-1, subsample=0.9, colsample_bytree=0.9,\n",
    "            min_child_samples=20, random_state=42\n",
    "        )\n",
    "        mdl.fit(X_tr, y_tr)\n",
    "\n",
    "        # ── base predictions ─────────────────────────────\n",
    "        cal_hat = mdl.predict(X_cal)\n",
    "        te_hat  = mdl.predict(X_te)\n",
    "\n",
    "        # ── split-conformal adjustment ───────────────────\n",
    "        resid = y_cal - cal_hat\n",
    "        if tau < 0.5:\n",
    "            adj = np.quantile(np.maximum(resid, 0), 1 - tau)\n",
    "            te_adj = te_hat - adj\n",
    "        elif tau > 0.5:\n",
    "            adj = np.quantile(np.maximum(-resid, 0), 1 - (1 - tau))\n",
    "            te_adj = te_hat + adj\n",
    "        else:                       # τ = 0.50\n",
    "            te_adj = te_hat\n",
    "\n",
    "        # ── per-row predictions ──────────────────────────\n",
    "        fold_pred.extend({\n",
    "            \"timestamp\": g.loc[i, \"timestamp\"],\n",
    "            \"token\":     token_id,\n",
    "            \"tau\":       tau,\n",
    "            \"y_true\":    yt,\n",
    "            \"y_pred\":    yp\n",
    "        } for i, yt, yp in zip(te_idx, y_te, te_adj))\n",
    "\n",
    "        # ── fold-level pinball loss ──────────────────────\n",
    "        err = y_te - te_adj\n",
    "        pin = np.maximum(tau*err, (tau-1)*err).mean()\n",
    "        fold_res.append({\n",
    "            \"token\":   token_id,\n",
    "            \"tau\":     tau,\n",
    "            \"pinball\": pin\n",
    "        })\n",
    "\n",
    "    return fold_pred, fold_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d879e5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=23)]: Using backend LokyBackend with 23 concurrent workers.\n",
      "[Parallel(n_jobs=23)]: Done   6 out of  21 | elapsed:    6.6s remaining:   16.7s\n",
      "[Parallel(n_jobs=23)]: Done  11 out of  21 | elapsed:    6.7s remaining:    6.1s\n",
      "[Parallel(n_jobs=23)]: Done  16 out of  21 | elapsed:    6.8s remaining:    2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau\n",
      "0.05    0.0359\n",
      "0.25    0.0655\n",
      "0.50    0.0659\n",
      "0.75    0.0884\n",
      "0.95    0.0601\n",
      "Name: pinball, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=23)]: Done  21 out of  21 | elapsed:    8.1s finished\n"
     ]
    }
   ],
   "source": [
    "def run_token(tok, grp):\n",
    "    preds, metrics = [], []\n",
    "    for tr, cal, te in rolling_splits(grp.index):\n",
    "        p, m = fit_one_fold(grp, tr, cal, te)\n",
    "        preds.extend(p); metrics.extend(m)\n",
    "    return preds, metrics\n",
    "\n",
    "n_jobs = max(os.cpu_count()-1, 1)\n",
    "results = Parallel(n_jobs=n_jobs, verbose=5)(\n",
    "    delayed(run_token)(tok, grp.reset_index(drop=True))\n",
    "    for tok, grp in df.groupby(\"token\"))\n",
    "\n",
    "preds   = list(itertools.chain.from_iterable(r[0] for r in results))\n",
    "metrics = list(itertools.chain.from_iterable(r[1] for r in results))\n",
    "\n",
    "pd.DataFrame(preds).to_csv(\"stage7_lgb_preds.csv\", index=False)\n",
    "pd.DataFrame(metrics).to_csv(\"stage7_lgb_pinball.csv\", index=False)\n",
    "\n",
    "print(pd.DataFrame(metrics)\n",
    "        .groupby(\"tau\")[\"pinball\"].mean()\n",
    "        .round(4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
