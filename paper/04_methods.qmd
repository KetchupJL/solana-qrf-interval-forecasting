# Methods

This chapter details the modelling and evaluation framework used to forecast 72-hour log-returns for mid-cap Solana tokens. Building on last section, we specify the conditional-quantile models, the leakage controls, and the blocked walk-forward design under which all models are trained and evaluated. All formulas, definitions and notations are summarised in Appendix 2.

*See Appendix 2 and the respective sections within Appendix 4 (Figures) and 5 (Code) for additional supporting content*

Our predictive target is the 72-hour log-return defined in the last section. To avoid redundancy we refer to that definition and denote the conditional quantile function at level $\tau$ by $q_\tau(x)$ and its estimator by $\widehat q_\tau(x)$. All models are trained per token (no cross-sectional pooling) using only that token’s own history. The design matrix uses the pruned feature-set v1, with numeric columns standardised on the Train slice only; categorical indicators are one-hot encoded with an intercept.

## Rolling design, feature set, and leakage controls {#sec-rolling}

**Blocked walk-forward.** For each token we use:

- **Train:** 120 bars (~60 days)  
- **Calibrate:** 24 bars (non-crossing + band calibration only)  
- **Test:** 6 bars (72 h)  
- **Step:** 6 bars (non-overlapping Test windows)

Features at time $t$ use only information available by the close of bar $t$; the target is $y_{t+6}$. We report both micro and macro averages across tokens; precise formulas in Appendix 2.

**Feature set & leakage controls.** We use feature-set v1 (29 predictors) grouped into momentum, volatility, liquidity/flow, on-chain activity, and market context. Rolling statistics and lags are computed with windows that end at $t$; the design matrix at $t$ excludes any information from $t{+}1…t{+}6$. 
*The full feature dictionary can be see in Appendix 2 (Table 4).*

**Global non-crossing & calibration.** Base quantiles are made monotone in $\tau$ via row-wise isotonic rearrangement (pool-adjacent-violators), then central bands are adjusted using split-conformal prediction on the 24-bar calibration slice. Score definitions and order-statistic inflation for the 80% and 90% bands are given in Appendix 2.

**Software.** Library and environment details are listed in Appendix 4.

#### Model Building

We present a compact, self-contained statement of each model (objective/estimator) in the main text, with derivations and implementation details in Appendix 2. The core validation metrics—pinball loss, reliability, and interval coverage/width, are defined in the main text; the full DM–HAC with HLN specification appears in Appendix 2. All figures are collected in Appendix 4, and all applied code is provided in Appendix 5.

## Linear Quantile Regression Model (Baseline)

**Estimator.**  For each quantile $\tau$ in the chosen set we fit a linear quantile regression model using the Koenker–Bassett formulation.  In the rolling back‑test reported here the quantile grids were $\{0.05,0.25,0.50,0.75,0.95\}$ for the main baseline and $\{0.10,0.50,0.90\}$ for a simpler variant.  For each $\tau$ we solve

$$
\widehat\beta_\tau = \arg\min_{\beta\in\mathbb{R}^p} \sum_{t\in\text{Train}} \rho_\tau(y_t - \mathbf{x}_t^{\top}\beta), \quad \rho_\tau(u) = u\,(\tau-\mathbf{1}\{u<0\}),
$$

with no regularisation.  The models are fitted with `statsmodels.QuantReg`.

**Design matrix & fitting.**  We use the “features v1” data set.  Numeric predictors are scaled within each training window using a robust scaler or standard scaler depending on the notebook; categorical predictors (such as token identifier, momentum bucket, day of week, etc.) are one‑hot encoded with the first level dropped.  An intercept term is added by `sm.add_constant`.  The pre‑processor is fit only on the training slice and then applied to the calibration and test slices.

**Non‑crossing.**  In the variant with three quantiles, we apply a simple post‑hoc non‑crossing adjustment so that the 10th‑percentile predictions never exceed the median and the 90th‑percentile predictions never fall below it.  No isotonic rearrangement across a larger grid of quantiles was used in these baselines.

#### Reporting
We report **pinball loss** by $\tau$, **reliability** (empirical $\widehat F_\tau$ vs nominal $\tau$), **coverage/width** at 80%/90%, and **Diebold–Mariano** tests vs. LightGBM and QRF. See appendix 4 for varient analysis and extra figures.


#### Variants: LQR variants (pinball at key quantiles)** {#tbl-lqr-variants}

| Variant    | Estimator           | Non-crossing | Calibration | Pinball (τ=.10 / .50 / .90) |
|:-----------|:--------------------|:------------:|:-----------:|:----------------------------|
| **LQR v1** | statsmodels QuantReg |      O       |      X      | — / **8.0238** / —          |
| **LQR v2** | statsmodels QuantReg |      X      |      X      | **0.0400** / **0.0640** / **0.3850** |


**Why this baseline.** LQR provides a transparent parametric benchmark. In heavy-tailed, skewed crypto returns, its characteristic tail mis-calibration (see @fig-lqr-calibration in Appendix 2) motivates the flexible, non-parametric models.


## Gradient-boosted trees with quantile loss (LightGBM baseline) {#sec-lgbm}

**Estimator (pinball objective).**
For each quantile $\tau$, we fit a gradient-boosted tree model that minimizes the pinball loss. At boosting step $m$, the predictor updates as $F^{(\tau)}_{m}(x) = F^{(\tau)}_{m-1}(x) + \eta\,f^{(\tau)}_{m}(x)$, where the regression tree $f^{(\tau)}_{m}$ is trained on pseudo-residuals $g^{(\tau)}_{t} = \tau - \mathbf{1}\{y_t < F^{(\tau)}_{m-1}(x_t)\}$.

**Design matrix and tuning.**
In the v1 baseline, we pass numeric features unchanged and one-hot encode categorical variables via a `ColumnTransformer`. We fix hyperparameters (`n_estimators=500`, `learning_rate=0.05`, `subsample=0.9`, `colsample_bytree=0.9`, `min_child_samples=20`) and fit models for $\tau\in\{0.05,0.25,0.50,0.75,0.95\}$.
In v2, we tune hyperparameters per quantile with Optuna over `num_leaves`, `max_depth`, `min_data_in_leaf`, `learning_rate`, and sampling fractions; categorical features are cast to pandas `Categorical` so LightGBM handles them natively.
In later variants (v3/v4), we re-fit with the v2-selected settings, deepen trees (e.g., `max_depth=10`), and enable early stopping.

**Calibration and non-crossing.**
We apply conformal quantile regression to all LightGBM variants. v1–v2 use **split-conformal** adjustments (one-sided shifts of lower/upper quantiles). v3–v4 use **CV-plus** (two-sided) calibration with residual winsorization, and we exclude calibration rows with high imputation fractions. We do not apply isotonic rearrangement; non-crossing is therefore not enforced explicitly.

**Reporting.**
For each $\tau$, we report pinball loss; for intervals, we report empirical coverage and mean half-width of the 80% prediction interval. v3 additionally includes Diebold–Mariano tests for model comparisons.

#### Variants

| Variant        | Tuning     | Calibration            | Pinball (key τ)                          | Cov. 80% |
|:---------------|:-----------|:-----------------------|:-----------------------------------------|---------:|
| **v1 (base)**  | Fixed      | Split-conformal        | ≈ 0.0359 (@.05), 0.0659 (@.50), 0.0601 (@.95) |      n/a |
| **v2 (tuned)** | Optuna per τ | Split-conformal      | ≈ 0.0553 (@.10), 0.0656 (@.50), 0.0778 (@.90) |   ≈97.5% |
| **v4 (final)** | v2 params + ES | CV-plus, winsorised | ≈ 0.0316 (@.10), 0.0473 (@.25), 0.0755 (@.75) |   ≈82.9% |


**Why this baseline.** Quantile LightGBM is a strong, non-linear comparator that is fast, interaction-aware, and—after split-conformalisation—near-nominal in coverage with comparatively tight bands, setting a demanding reference for QRF (§4.4).


## Quantile Regression Forests (core model) {#sec-qrf}
**Estimator.**
For each query point $x$, we fit a Quantile Regression Forest (QRF) as an ensemble of regression trees and define observation weights $w_t(x)$ over training responses $y_t$ that share terminal nodes with $x$. The conditional distribution $\hat F_x(\cdot)$ is the empirical CDF of these weighted responses, and the $\tau$-level quantile is

$$
\hat q_\tau(x)\;=\;\inf\Bigl\{q:\;\sum_{t\in\text{train}} w_t(x)\,\mathbf{1}\{y_t\le q\}\ge \tau\Bigr\}.
$$

**Time-decay weighting.**
To emphasize recent information, we apply exponentially decaying sample weights with half-life $h=60$ bars. If $\Delta t$ denotes the age (in 12-hour bars) of observation $t$, we set $\omega_t \propto 2^{-\Delta t/h}$ and normalize so that $\sum_t \omega_t=1$. These $\omega_t$ are supplied to the forest via `sample_weight`.

**Preprocessing and tuning.**
Categorical predictors (`token`, `momentum_bucket`, `day_of_week`, `tail_asym`, `extreme_flag1`, `vol_regime`) are one-hot encoded; numerical predictors are standardized. A single Optuna study searches over the number of trees, maximum depth, minimum samples per leaf, and feature subsampling to minimize average pinball loss across quantiles and rolling folds. The tuned specification typically selects $\sim\!1050$ trees with relatively deep depth and small leaf size.

**Calibration and non-crossing.**
Raw QRF quantiles can cross and often over-cover. We therefore apply:

1. **Isotonic regression.** After predicting $\{q_{\tau_i}(x)\}_{i=1}^m$, we fit a one-dimensional isotonic regression along the quantile axis to enforce monotonicity, which preserves spacing better than simple sorting.
2. **Regime-aware residual quantile calibration.** For each rolling window, we compute residuals on a 24-bar calibration slice, winsorize them, stratify by a volatility-regime indicator (`vol_regime`), and estimate separate residual quantiles for “quiet” and “volatile” periods. Lower/upper quantiles (e.g., 0.10 and 0.90) are adjusted by the appropriate residual quantile; a median-bias correction is applied at $\tau=0.50$. Calibration rows with >30% imputed features are excluded.
3. **Split-conformal top-up.** To obtain two-sided $(1-\alpha)$ prediction intervals (e.g., 80% and 90%), we use split-conformal adjustments: we add the $\lceil (n+1)\alpha\rceil$-th largest positive residual to the upper bound and subtract the corresponding negative residual from the lower bound, yielding finite-sample, distribution-free coverage.

**Reporting and variants.**
We evaluate via rolling-window cross-validation (train 120 bars, calibrate 24, test 6). We report per-quantile pinball loss, empirical coverage, and average interval width, and use Diebold–Mariano tests to compare QRF with linear QR and LightGBM.


| Variant                     | Time-decay | Non-crossing | Calibration                                                | τ=0.10 pinball | τ=0.50 pinball | τ=0.90 pinball |
|----------------------------|:----------:|:------------:|------------------------------------------------------------|---------------:|---------------:|---------------:|
| **QRF-v1 (base)**          | O          | sort         | none                                                       | 0.0286         | 0.0725         | 0.0682         |
| **QRF-v2 (CQR + regime)**  | X          | isotonic     | regime-aware residual quantile + split-conformal           | 0.0224         | 0.0610         | 0.0660         |
| **QRF-v3 (tuned)**         | X          | isotonic     | same as v2                                                 | ≈ 0.0229       | ≈ 0.0653       | ≈ 0.0670       |
| **QRF-v4 (final)**         | X          | isotonic     | regime-aware residual quantile + split-conformal (CV-plus) | 0.0224         | 0.0610         | 0.0660         |


**Final specification and rationale.**
We adopt the tuned, time-decay QRF (v4) as the core model. It combines (i) isotonic enforcement across quantiles, (ii) regime-aware residual quantile offsets with winsorization and exclusion of heavily imputed rows, and (iii) a small split-conformal top-up to achieve nominal coverage. This preserves per-quantile reliability and yields central intervals that are sharper than the LightGBM baseline (see §5): pinball loss at $\tau\in\{0.10,0.90\}$ is \~0.022 and 0.066, and the median-level loss (\~0.061) matches the boosted baseline.

**All model-variant figures and additional analyses are provided in Appendix 4 (Extras).**

## Validation, metrics, and statistical tests

This section formalises the criteria used to compare models. Definitions and notations are in Appendix 2.

#### Losses and calibration metrics

**Pinball loss.** Primary score for each $\tau$; we report per-$\tau$ means (with dispersion across tokens/folds) and a composite average over $\mathcal T=\{0.05,0.10,0.25,0.50,0.75,0.90,0.95\}$.

**Empirical coverage & average width.** For central $(1-\alpha)$ bands (after non-crossing and calibration) we report coverage, average width, and **coverage error** $|\widehat{\mathrm{cov}}-(1-\alpha)|$. We also examine **conditional coverage** by deciles of predicted width.

**Quantile reliability / calibration curves.** We plot empirical hit-rates $\widehat F_\tau$ against nominal $\tau$; the ideal line is 45°.

**Proper scoring rule.** We include the **interval score** (Gneiting–Raftery, 2007) for completeness.

*See Appendix 2 table 3 for definitions*

#### Statistical comparisons

Pairwise comparisons use **Diebold–Mariano** tests on pinball-loss differentials with **Newey–West** HAC variance and the **Harvey–Leybourne–Newbold** small-sample correction. ([Newey1987] [@Harvey1997])

We further build on this test using the **Model Confidence Set** by [@Hansen2011].
*See Appendix 2 table 3 for definitions*

#### Additional analyses: regimes, conditional coverage, and efficiency

The global scores above average over heterogeneous market states and tokens. To better understand the adaptivity and economic value of interval forecasts, we perform several sliced analyses on the Test forecasts:

- **Regime analysis.** We stratify Test observations into **quiet**, **mid**, and **volatile** windows based on realised-volatility terciles. Within each regime we recompute empirical coverage, mean width, and reliability curves. This assesses whether models widen bands appropriately in turbulent markets and is visualised by regime-specific calibration curves (see Results `@fig-reliability-regime`).

- **Conditional coverage by predicted width.** For each model and central interval, we sort forecasts into deciles of predicted band width. We then compute hit-rates within each decile to test whether wider intervals indeed cover more outcomes. A monotonically increasing hit-rate confirms that the model’s widths are informative about uncertainty. The decile table and associated plot are reported in the Results (Fig. `@fig-cond-cov-width`; Table `@tbl-condcov-width`).

- **Sharpness–coverage efficiency.** We summarise each model–interval pair by its average width and empirical coverage and display points on the efficiency plane (coverage on the y-axis, width on the x-axis). Points closer to the upper-left (high coverage and low width) are preferred. See Results (Fig. `@fig-efficiency-scatter`; Table `@tbl-efficiency-summary`) for the scatter and summary.

These additional analyses complement the global averages by revealing regime-dependent behaviour, the information content of predicted widths, and the sharpness–coverage trade-off.

#### Robustness tests and ablations

We assess stability via **component-wise ablations** of the final QRF:

- **Decay weights (ON/OFF).** Remove exponential time-decay (baseline half-life 60 bars).
- **Calibration wrapper.** Replace residual-quantile offsets + split-conformal with pure split-conformal.
- **Monotone rearrangement.** Disable isotonic non-crossing.
- **Half-life sensitivity.** Test 30 and 90 bars around the baseline.
- **Calibration scope.** Compute residual offsets per token (final) vs pooled.

For each toggle we report deltas in mean pinball, coverage (80%/90%), and width relative to QRF-final, with HAC-adjusted DM tests for significance.

#### Cross-sectional heterogeneity and per-token diagnostics

To avoid dominance by long or high-volume series, we summarise per-token pinball, coverage, and width across all Test windows, show their dispersion (boxplots), and include representative fan charts (q05–q95) illustrating adaptivity. See Results Fig. `@fig-pinball-by-token`, `@fig-fan-mlg`, `@fig-fan-ava`.

## Application: interval-aware sizing
We outline a position-sizing rule that scales exposure inversely with predicted interval width, subject to risk limits; implementation and back-test appear in Results.

