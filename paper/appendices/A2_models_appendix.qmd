# Appendix 2: Methodology Appendix

This appendix collects the notation, model definitions, calibration procedures, metrics, and statistical tests referenced in Chapter 4. Hyper-parameter tables, software details, and the moved feature dictionary table are also registered here for cross-referencing.

#### Notation & rolling design {#app-m0-notation}

**Indices and data.** At 12-hour index $t$, let features be $x_t\in\mathbb{R}^p$ and the 72-hour ahead target be $y_t$. For a quantile level $\tau\in(0,1)$, the conditional quantile is $q_\tau(x)$ and its estimator is $\widehat q_\tau(x)$. The quantile grid is $\mathcal T=\{0.05,0.10,0.25,0.50,0.75,0.90,0.95\}$.

**Rolling windows.** For each token, non-overlapping **Test** windows are produced by stepping 6 bars through a **Train–Calibrate–Test** split:
- Train: 120 bars (~60 days)
- Calibrate: 24 bars (used only for non-crossing and calibration)
- Test: 6 bars (72 h), step = 6 bars

**Causality.** Features at time $t$ use only information up to the $t$ close; the target is $y_{t+6}$.

**Averaging.** For a per-prediction loss $\ell_{i,t}$ (token $i$, time $t$):
$$
\text{micro}=\frac{\sum_i\sum_{t\in\mathrm{Test}_i}\ell_{i,t}}{\sum_i|\mathrm{Test}_i|},
\qquad
\text{macro}=\frac{1}{N}\sum_{i=1}^N \left(\frac{1}{|\mathrm{Test}_i|}\sum_{t\in\mathrm{Test}_i}\ell_{i,t}\right).
$$

---

**Pinball loss {#app-m1-pinball}**

**Definition (Koenker & Bassett, 1978).**  For prediction $\widehat q_{\tau}(x)$ and residual $u=y-\widehat q_{\tau}(x)$,

$$
\rho_{\tau}(u) = u\big(\tau - \mathbf{1}\{u<0\}\big).
$$

This loss is minimized by Linear Quantile Regression and is the primary evaluation metric for all models.

---

**Pinball loss & non-crossing {#app-m1-pinball}**

**Pinball loss.** For residual $u$, 
$$
\rho_\tau(u) \;=\; u\big(\tau-\mathbf{1}\{u<0\}\big),
\qquad
\text{and}\quad 
\text{Pinball}_\tau=\frac{1}{T_\text{test}}\sum_{t\in\mathrm{Test}}\rho_\tau\!\big(y_t-\widehat q_\tau(x_t)\big).
$$

---

**Isotonic rearrangement {#app-m1-isotonic}**

Given raw $\{\widehat q_{\tau_k}(x)\}_{k=1}^K$ at increasing $\{\tau_k\}$, the non-decreasing projection $\{\tilde q_{\tau_k}(x)\}$ solves
$$
\tilde q_{\tau_k}(x) \;=\; \operatorname*{arg\,min}_{g:\,\text{nondecreasing}} 
\sum_{k=1}^K \big(\widehat q_{\tau_k}(x)-g(\tau_k)\big)^2,
\qquad
\tilde q_{\tau_1}(x)\le\cdots\le \tilde q_{\tau_K}(x).
$$

---

**Split-conformal calibration of central bands {#app-m2-conformal}**

On a calibration slice of size $m$ with rearranged base quantiles $\tilde q_\ell,\tilde q_u$, define two-sided scores
$$
s_t=\max\{\tilde q_\ell(x_t)-y_t,\; y_t-\tilde q_u(x_t)\},\quad t=1,\dots,m,
$$
and the order-statistic inflation 
$$
\delta_\alpha = s_{(\lceil (m+1)(1-\alpha)\rceil)}.
$$
The $(1-\alpha)$ conformalised interval is
$$
\big[\tilde q_\ell(x)-\delta_\alpha,\;\tilde q_u(x)+\delta_\alpha\big],
$$
which attains finite-sample marginal coverage $\ge 1-\alpha$ under exchangeability. (One-sided tails are analogous.)

---

## Model Formulations

**Quantile Regression Forest details {#app-m3-qrf}**

Let $\{(x_j,y_j)\}_{j=1}^n$ be training pairs and let $\mathcal F = \{ T_b \}_{b=1}^B$ be a forest of $B$ trees.  For query $x$, each tree assigns $x$ to a leaf $\mathcal L_b(x)$ containing a subset of training points.  Define weights

$$
 w_j(x) = \frac{1}{B} \sum_{b=1}^{B} \frac{\mathbf{1}\{ x_j \in \mathcal L_b(x) \}}{ |\mathcal L_b(x)| },
 \qquad
 \sum_{j=1}^n w_j(x) = 1,
$$

and estimate the conditional CDF as $\widehat F(y\mid x) = \sum_{j=1}^n w_j(x)\,\mathbf{1}\{ y_j \le y \}$.  The conditional quantile estimator is

$$
\widehat q_{\tau}(x) = \inf\big\{ z : \widehat F(z\mid x) \ge \tau \big\}.
$$

**Time‑decay reweighting.**  To emphasise recent observations, sample weights $\pi_j$ are applied when training each tree.  For relative age $\Delta t$, the weight decays exponentially with half‑life $h$ bars:

$$
\pi_j \propto 2^{-\Delta t/h},
\quad\text{normalised so that}\quad \sum_j \pi_j = 1.
$$
These weights enter both split selection and the leaf distributions.  The final forest hyper‑parameters and search ranges are summarised in Table 1.


**Notes on QRF implementation and calibration {#app-m3-qrf-notes}**

In addition to the estimator definitions given in Appendix M3, this section records details of the Quantile Regression Forest implementation and calibration:

- **Hyper‑parameters and search.**  The search ranges and final values for `n_estimators`, `max_depth`, `min_samples_leaf`, `max_features`, `bootstrap`, and `random_state` are summarised in Table `@tbl-qrf-hparams`.  A global Optuna study minimising mean pinball loss selected the winning configuration.
- **Calibration.**  Residual‑quantile calibration (RQC) offsets are computed separately for each regime (quiet/mid/volatile).  Split‑conformal bands are also formed as a robustness check.  
- **Implementation notes.**  A single shared forest supplies quantiles at all levels; per‑tree sample weights implement exponential time‑decay.  Code is provided in the listings referenced below.

**See appendix 4 for all figures and tables related to QRF**

![QRF v3 reliability by regime; each line shows empirical hit-rate vs nominal τ for a regime; ideal line shown.](figures/final/fig-qrf-v3-reliability-by-regime.pdf){#fig-qrf-v3-reliability-by-regime fig-align="center" width="70%"}

![QRF v1 mean pinball loss per quantile.](figures/final/fig-qrf-v1-pinball-mean.pdf){#fig-qrf-v1-pinball-mean fig-align="center" width="62%"}


**QRF implementation notes {#app-r4-qrf-code}**

See Appendix 5 for full Model code

**QRF variants and hyper‑parameters {#app-t3-qrf-hparams}**

This section collects the hyper‑parameter search ranges, final values and variant metrics for the Quantile Regression Forest (QRF) models referenced in Chapter 4.  Use this table to reproduce the model specifications and to understand the trade‑offs explored in the robustness checks.

**Table 1**

| Parameter            | Value                |
|:---------------------|:---------------------|
| n_estimators         | 1467                 |
| max_depth            | 24                   |
| min_samples_leaf     | 5                    |
| max_features_choice  | fraction             |
| max_features         | 0.9984302781608038   |


---

**Linear Quantile Regression optimisation {#app-l1-lqr}**

**Problem statement.**  For each quantile level $\tau$ and feature vector $x$, LQR solves

$$
\widehat{\beta}_{\tau} = \arg\min_{\beta\in \mathbb{R}^{p+1}} \sum_{t\in\mathcal{T}_{\text{train}}} \rho_{\tau}\big( y_{t} - [1,x_{t}]^{\top}\beta \big),
\quad
\widehat q_{\tau}(x) = [1,x]^{\top} \widehat{\beta}_{\tau}.
$$

The pinball loss $\rho_{\tau}$ is defined in Appendix M1.  Each $\tau$ is fit independently.

**Design notes.**  Numeric predictors are standardised using training statistics; categorical variables are one‑hot encoded with an intercept.  No further transformations are applied.  Convergence and solver settings for `statsmodels.QuantReg` are summarised below.

![Linear-QR 72-hour forecast fan chart for the token BOME.](figures/final/fig-lqr-fan-longest.pdf){#fig-lqr-fan-longest fig-align="center" width="72%"}

![Coverage of 80% prediction intervals across folds; dashed line marks nominal 80%.](figures/final/fig-lqr-coverage-80pi-hist.pdf){#fig-lqr-coverage-80pi-hist fig-align="center" width="62%"}

![Linear-QR calibration: empirical vs nominal coverage (ideal line shown).](figures/final/fig-lqr-v1-calibration.pdf){#fig-lqr-calibration fig-align="center" width="64%"}

---

**LightGBM quantile objective and boosting {#app-g1-lgbm-obj}**

**Boosting update.**  Let $F_m^{(\tau)}(x)$ denote the stage‑$m$ prediction for quantile level $\tau$.  Gradient boosting updates via

$$
F_{m}^{(\tau)}(x) = F_{m-1}^{(\tau)}(x) + \eta\, f_{m}^{(\tau)}(x),
$$

where $f_{m}^{(\tau)}$ is a regression tree and $\eta\in(0,1]$ is the learning rate.

**Negative gradient for the pinball loss.**  For residual $u_t = y_t - F_{m-1}^{(\tau)}(x_t)$,

$$
 g_{t}^{(\tau)} = -\frac{\partial}{\partial \hat y}\,\rho_{\tau}(u_t)\Big|_{\hat y = F_{m-1}^{(\tau)}(x_t)} = \tau - \mathbf{1}\{ y_t < F_{m-1}^{(\tau)}(x_t) \}.
$$

LightGBM fits $f_{m}^{(\tau)}$ to $(x_t,g_t^{(\tau)})$ using histogram‑based splits and leaf‑wise growth; second‑order terms vanish for the pinball loss, so a first‑order update suffices.


**Table 2 — LightGBM hyper‑parameters by quantile {#app-t2-lgbm-hparams}**

| τ    | lr      | leaves | depth | min_leaf | feat_frac | bag_frac | bag_freq |   L1       |    L2      | gamma | iters |
|:----:|:--------|------:|------:|---------:|----------:|---------:|---------:|-----------:|-----------:|------:|------:|
| 0.05 | 0.01078 |   253 |     4 |       96 |     0.762 |    0.711 |        4 | 8.15e-06   | 2.09e-07   | 0.069 |  2449 |
| 0.10 | 0.00622 |    91 |    13 |       37 |     0.862 |    0.714 |       15 | 2.6940     | 0.5684     | 0.172 |  7495 |
| 0.25 | 0.00783 |    42 |     6 |       79 |     0.622 |    0.963 |       11 | 0.01731    | 0.8099     | 0.085 |  7999 |
| 0.50 | 0.01376 |    56 |     5 |       22 |     0.960 |    0.796 |       11 | 3.95e-06   | 3.85e-07   | 0.333 |  7992 |
| 0.75 | 0.05456 |    68 |     9 |       76 |     0.520 |    0.994 |        1 | 5.21e-08   | 1.94e-04   | 0.060 |  1095 |
| 0.90 | 0.04030 |    96 |     7 |       78 |     0.909 |    0.445 |        2 | 3.49e-05   | 3.41e-05   | 0.191 |   218 |
| 0.95 | 0.00617 |   201 |     4 |        8 |     0.776 |    0.990 |        3 | 0.00117    | 4.83e-06   | 0.162 |  3200 |


![LightGBM-CQR v4 fan chart with central median and central interval around the median; realised series overlaid. Compared to the V3 and V2, this shows the tightest intervals](figures/final/fig-lgbm-v4-fan-bome.pdf){#fig-lgbm-v4-fan-bome fig-align="center" width="72%"}

![Calibration of LightGBM-CQR v4: empirical CDF hits vs nominal τ; ideal line shown.](figures/final/fig-lgbm-v4-calibration.pdf){#fig-lgbm-v4-calibration fig-align="center" width="64%"}

**See appendix 4 for all figures and tables related to QRF**

---

### Statistical tests {#app-m4-tests}

**C with HAC and HLN.** Let $d_t$ be the loss differential (e.g., pinball) between models $A$ and $B$ at the same $\tau$ on Test. With $\bar d=\tfrac{1}{T}\sum_t d_t$ and Bartlett-weighted Newey–West spectral estimate
$$
\widehat S_L \;=\; \widehat\gamma_0 + 2\sum_{\ell=1}^{L}\left(1-\frac{\ell}{L+1}\right)\widehat\gamma_\ell,
\qquad
\widehat\gamma_\ell=\frac{1}{T}\sum_{t=\ell+1}^{T}(d_t-\bar d)(d_{t-\ell}-\bar d),
$$
the DM statistic is
$$
\mathrm{DM} \;=\; \frac{\bar d}{\sqrt{\widehat S_L/T}}.
$$
Small-sample **Harvey–Leybourne–Newbold (HLN)** correction is applied to obtain $p$-values. Two-sided tests are used throughout.

**Multiplicity.** Across multiple $\tau$ we control the false discovery rate with **Benjamini–Hochberg** at level $q$: sort p-values $p_{(1)}\le\cdots\le p_{(m)}$ and reject up to $k=\max\{i: p_{(i)}\le (i/m)q\}$. Holm–Bonferroni adjusted p-values are also reported.


**The Model Confidence Set**

The Model Confidence Set is an iterative, bootstrap-based procedure that tests the null of **Equal Predictive Ability** across models and sequentially removes the worst performer until the null cannot be rejected, yielding a **superior set** at confidence level $1-\alpha$. It controls for multiple comparisons and model-selection uncertainty, so instead of declaring a single “winner” it returns a statistically validated set; we apply it to rolling **pinball-loss** series across models and quantiles.


---

### Metric definitions {#app-m5-metrics}

**Coverage and width.**  For a central $(1-\alpha)$ interval $[L_t,U_t]$ on a Test window of length $T$, define

$$
\widehat{\mathrm{cov}} = \frac{1}{T} \sum_{t=1}^{T} \mathbf{1}\{ L_t \le y_t \le U_t \},
\qquad
\overline{\mathrm{width}} = \frac{1}{T} \sum_{t=1}^{T} (U_t - L_t).
$$

We also report the **coverage error** $|\widehat{\mathrm{cov}} - (1-\alpha)|$ and **conditional coverage** by deciles of predicted width.

**Quantile reliability.**  The empirical hit‑rate at quantile level $\tau$ is

$$
\widehat F_{\tau} = \frac{1}{T} \sum_{t=1}^{T} \mathbf{1}\{ y_t \le \widehat q_{\tau}(x_t) \}.
$$
Perfect calibration corresponds to $\widehat F_{\tau} = \tau$ for all $\tau$.

**Interval score**  For a central interval $[L_t,U_t]$ with nominal coverage $1-\alpha$ and observation $y_t$, the interval score (Gneiting & Raftery, 2007) is

$$
S_{\alpha}(L_t,U_t;y_t) = (U_t-L_t) + \frac{2}{\alpha} (L_t - y_t)\,\mathbf{1}\{ y_t < L_t \} + \frac{2}{\alpha} (y_t - U_t)\,\mathbf{1}\{ y_t > U_t \}.
$$
Lower values indicate sharper, better‑calibrated intervals.

---

**Table 3**

| Metric             | Definition (short)                                                                                 | Notes                      |
|:-------------------|:----------------------------------------------------------------------------------------------------|:---------------------------|
| Pinball loss       | $\rho_{\tau}(u)=u\big(\tau-\mathbf{1}\{u<0\}\big),\; u=y-\widehat q_{\tau}(x)$                     | Per-$\tau$; mean over $\mathcal T$ |
| Coverage           | $\widehat{\mathrm{cov}}=\tfrac{1}{T}\sum_{t=1}^{T}\mathbf{1}\{L_t\le y_t\le U_t\}$                  | Target $1-\alpha$          |
| Width              | $\overline{\mathrm{width}}=\tfrac{1}{T}\sum_{t=1}^{T}(U_t-L_t)$                                     | Pair with coverage         |
| Coverage error     | $\lvert \widehat{\mathrm{cov}}-(1-\alpha)\rvert$                                                    | Lower is better            |
| Reliability        | $\widehat F_{\tau}=\tfrac{1}{T}\sum_{t=1}^{T}\mathbf{1}\{y_t\le \widehat q_{\tau}(x_t)\}$           | Plot $\widehat F_{\tau}$ vs $\tau$ |
| Interval score     | $S_{\alpha}=(U-L)+\tfrac{2}{\alpha}(L-y)\mathbf{1}\{y<L\}+\tfrac{2}{\alpha}(y-U)\mathbf{1}\{y>U\}$ | Optional                   |


This table summarises the metrics referenced in the Methods and Results chapters.  See the definitions above and **Appendix @ref(app-m5-metrics)** for derivations.

---

**Table 4: Feature dictionary (full list of predictors) {#app-fdict}**

Table `@tbl-used-features` lists the complete set of features used in the modelling (feature‑set v1).  Each row gives the variable name, a brief description, and its family.  Use this as a reference when processing raw data and interpreting model coefficients.  

| Family                    | Feature Name         | Window | Description                |
| :------------------------ | :------------------- | :----: | :------------------------- |
| **Momentum**              | `logret_12h`         |    1   | 12-hour log return.        |
|                           | `logret_36h`         |    3   | 36-hour log return.        |
|                           | `proc`               |    –   | Price rate of change.      |
|                           | `rsi_14`             |   14   | Relative Strength Index.   |
|                           | `stoch_k`            |   14   | Stochastic %K.             |
|                           | `cci`                |    –   | Commodity Channel Index.   |
|                           | `macd`               |  12/26 | MACD (fast/slow EMA diff). |
|                           | `macd_signal`        |    9   | MACD signal line.          |
| **Volatility**            | `realized_vol_36h`   |    3   | Std. of `logret_12h`.      |
|                           | `vol_std_7bar`       |    7   | Rolling return std.        |
|                           | `downside_vol_3bar`  |    3   | Std. of negative returns.  |
|                           | `parkinson_vol_36h`  |    3   | Parkinson high–low vol.    |
|                           | `gk_vol_36h`         |    3   | Garman–Klass vol.          |
|                           | `atr_14`             |   14   | Average True Range.        |
|                           | `bollinger_bw`       |   20   | Bollinger band width.      |
|                           | `bollinger_b`        |   20   | Bollinger %B.              |
|                           | `rolling_skew_50`    |   50   | Skewness of returns.       |
|                           | `skew_36h`           |    3   | 36-hour return skewness.   |
|                           | `adx`                |    –   | Average Directional Index. |
| **Liquidity / Volume**    | `amihud_illiq_12h`   |    3   | Amihud illiquidity (36h).  |
|                           | `vol_zscore_14`      |   14   | Volume z-score.            |
|                           | `obv`                |    –   | On-Balance Volume.         |
| **On-Chain**              | `holder_growth_1bar` |    1   | % change in holders.       |
|                           | `holder_growth_7d`   |   14   | 7-day holder growth.       |
|                           | `tx_per_account`     |    –   | Tx per active holder.      |
| **Cross-Asset / Context** | `ret_SOL`            |    1   | SOL 12-h return.           |
|                           | `ret_ETH`            |    1   | ETH 12-h return.           |
|                           | `ret_BTC`            |    1   | BTC 12-h return.           |
|                           | `sol_return`         |    1   | SOL 12-h log return.       |
|                           | `corr_SOL_36h`       |    3   | Corr. to SOL returns.      |
| **Calendar / Time**       | `day_of_week`        |    –   | Categorical (0–6).         |
|                           | `hour_cos`           |    –   | Cyclical hour encoding.    |
| **Tail / Regime markers** | `extreme_flag1`      |    –   | Extreme-move indicator.    |
|                           | `extreme_count_72h`  |    6   | # extremes in past 72h.    |
|                           | `tail_asym`          |    –   | Tail asymmetry score.      |
|                           | `vol_regime`         |    –   | Quiet / volatile tag.      |
