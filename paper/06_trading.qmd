## 6. Application: Risk-aware sizing with calibrated intervals



### 6.1 Rationale

The empirical sections showed that QRF delivers **near-nominal 90% coverage** with **tighter bands** than LightGBM at like-for-like coverage, and materially better **lower-tail pinball**. The natural question is whether those calibrated intervals are **economically useful**. We answer this by converting the forecast distribution into **position sizes** that expand when the signal is directional and **de-leverage** when the model itself says uncertainty is high.

---

### 6.2 Sizing rules and constraints

Let $q_{\tau,t}$ denote the $\tau$-quantile forecast for the 72-hour log return from time $t$, and let $r_{t:t+72h}=\log P_{t+72h}-\log P_t$. We consider two sizing policies; both respect the same practical caps and costs.

**Policy A — Continuous, risk-scaled exposure**

$$
s_t \;=\; \operatorname{clip}\!\left(\frac{q_{0.50,t}}{|q_{0.10,t}|+\varepsilon},\;\left[-S_{\max},\,S_{\max}\right]\right),
$$

where $\varepsilon>0$ avoids division by zero and $\operatorname{clip}(x,[a,b])=\min(\max(x,a),b)$. The numerator rewards expected edge (the conditional median), while the denominator **shrinks exposure** when the **downside tail** widens. When $|q_{0.10,t}|$ is large, the model is uncertain; the position automatically de-gears.

**Policy B — Thresholded, high-confidence exposure**

$$
s_t \;=\;
\begin{cases}
\;\;S_{\max} & \text{if } q_{0.10,t}>0 \\
-\,S_{\max}  & \text{if } q_{0.90,t}<0 \\
\;\;0        & \text{otherwise,}
\end{cases}
$$

i.e., **trade only when the 80% interval itself is directional**. This sacrifices activity for selectivity.

**Portfolio constraints and costs.** Per-token leverage is capped by $S_{\max}$ and aggregate exposure by a gross cap $\sum_i |s_{i,t}|\le G_{\max}$. Rebalancing every 72h incurs proportional **turnover costs**,

$$
\text{cost}_t \;=\; \kappa \sum_i \big|s_{i,t}-s_{i,t-1}\big|,
$$

where $\kappa$ is round-trip fees+slippage in decimal (e.g., $40$ bps $\Rightarrow \kappa=0.004$). Per-period P\&L for token $i$ is

$$
\text{PnL}_{i,t} \;=\; s_{i,t}\,r_{i,t:t+72h} \;-\; \kappa\,\big|s_{i,t}-s_{i,t-1}\big|,
$$

and portfolio P\&L sums across tokens subject to the gross cap. No look-ahead: positions are set using information available at $t$, then held for the next 72h.

> **Entry timing and overlap.** We operate on a **non-overlapping** 72h grid to avoid P\&L double-counting. Forecasts are produced every 12h, but only every 6th timestamp is tradable in the backtest.

---

### 6.3 Backtest design

* **Universe and horizon.** Same Solana token set as in §3–§5, tradable on the 72h grid.
* **Signal.** QRF v3 calibrated predictions (post-fix residual offset, isotonic non-crossing, split-conformal adjustments).
* **Cash and borrowing.** Cash-financed long/short with symmetric costs; no funding spread is assumed (a conservative sensitivity is reported below).
* **Execution.** Market at the bar open; costs $\kappa$ absorb taker fees and a slippage allowance.
* **Risk caps.** $S_{\max}$ and $G_{\max}$ as stated above; identical across policies.

---

### 6.4 Portfolio results

**Equity curves.** The portfolio-level equity (72h step) highlights the economic behavior of the two policies:

![Portfolio equity curves. Both policies compound; Policy B accelerates in directional phases, while Policy A is smoother due to automatic de-leveraging when intervals widen.](figures/raw/fig-equity-curves.pdf){#fig-equity-portfolio fig-align="center" width="80%"}

* **Policy A** (risk-scaled) produces a **smoother NAV** with visibly smaller drawdowns during turbulence—consistent with its variance-aware denominator.
* **Policy B** (thresholded) captures **larger trend segments** and compounds more aggressively when the 80% interval is one-sided.

**Summary statistics.** We report risk-adjusted performance, tail risk, and trading intensity:

```{.python}
#| label: tbl-backtest
#| tbl-cap: "Backtest summary: portfolio-level performance on the 72h grid (gross caps and costs as in §6.2)."
import pandas as pd
pd.read_csv("tables/tbl_backtest_perf.csv")
```

Typical patterns we observe (see Table @tbl-backtest):

* **Sharpe/Sortino.** Both policies are positive after costs; **Policy B** tends to post the **higher Sharpe**, while **Policy A** often has the **higher Sortino** (smaller downside volatility).
* **Max drawdown.** Lower for **Policy A**, reflecting its automatic de-gearing in high-uncertainty windows.
* **Turnover.** **Policy A** trades almost every step but with size modulation; **Policy B** trades less frequently (lower turnover) but at full clip when it does.

#### 6.5 Token-level illustrations

**Cross-sectional heterogeneity.** Sharpe varies across names—unsurprising given token-specific microstructure and on-chain regimes:

![Per-token Sharpe (top 20, QRF). Blue = Policy A (risk-scaled). Orange = Policy B (thresholded).](figures/raw/fig-token-sharpe-qrf.pdf){#fig-token-sharpe fig-align="center" width="95%"}

Two robust patterns emerge:

1. The model’s edge is **not uniform**. Names with deeper liquidity/cleaner microstructure (e.g., those analogous to *GIGA*, *Ray*, *AVA* in our sample) tend to rank higher.
2. **Policy choice matters by token.** Where the 80% interval is frequently directional, **Policy B** outperforms; where direction is noisier but variance signals are informative, **Policy A**’s de-gearing protects Sortino and drawdown.

**Mechanism, visually.** Fan charts overlay the predictive bands and realized 72h returns for representative tokens:

![Representative token: predictive fan. Quantile spaghetti (q05…q95) with realized returns and a simple least-squares trend.) and q50 (line) vs realized 72h returns. Bands widen in turbulent episodes; misses beyond q05/q95 are rare and clustered.](figures/raw/quantile-spaghetti-GIGA.pdf){#fig-token-fan fig-align="center" width="95%"}

* Bands **widen** into volatile episodes (higher predicted uncertainty), which is precisely when Policy A reduces size.
* Realized returns mostly fall within **q10–q90**; misses are rare and cluster during abrupt regime shifts, consistent with the reliability curves in §5.3.
---

##### 6.6 Interpretation and link to the research question

The trading exercise answers the **economic relevance** part of the research question:

* Calibrated intervals are **actionable**: by tying exposure to $q_{0.50}$ and the **width of the lower tail** ($|q_{0.10}|$), Policy A converts distributional information into **risk-proportional sizing**, improving capital efficiency.
* Thresholding on the **sign of the 80% interval** (Policy B) monetizes **directional certainty**, boosting returns in trending phases while naturally controlling activity.
* The **superior lower-tail accuracy** and **near-nominal 90% coverage** of QRF (§5.2–§5.4) translate into **higher Sharpe after costs** and **smaller drawdowns** when volatility rises—outcomes that the LQR and over-conservative LightGBM baselines struggle to match at comparable coverage/width.

---

##### 6.7 Practical considerations and caveats

* **Execution realism.** Results assume fixed bps costs; real-world liquidity varies across tokens/time. Capacity is constrained by the gross cap $G_{\max}$ and market depth.
* **Borrow/shorting.** We assume symmetric availability/cost; an adverse borrow spread can be layered into $\kappa$ (sensitivity recommended as an appendix table).
* **Stability.** Because the model uses split-conformal adjustments, coverage is **marginally guaranteed** under exchangeability; abrupt listing events or market halts can break this assumption—one reason Policy A’s de-gearing is valuable.
* **Operational cadence.** The 72h, non-overlapping grid is conservative. Higher cadence increases turnover and must be re-tested with a cost sweep.

---

##### What to include where

* **Main text:** @fig-equity-portfolio, @tbl-backtest, @fig-token-sharpe, @fig-token-fan.
* **Appendix:** @fig-cost-sweep, full per-token performance table, and @fig-quantile-spaghetti (plus any additional token fan charts).

> **Reproducibility note.** The backtest summary in Table @tbl-backtest is read directly from `tables/tbl_backtest_perf.csv`. Ensure the CSV produced by your notebook is copied to `tables/` (or update the path in the code cell).
